<!DOCTYPE html>
<html>
<head>
	<title>Portfolio website</title>
	<link rel="stylesheet" type="text/css" href="../css/datagath_style.css">

	<link rel="preconnect" href="https://fonts.gstatic.com">
  <link href="https://fonts.googleapis.com/css2?family=Josefin+Sans:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;1,100;1,200;1,300;1,400;1,500;1,600;1,700&display=swap" rel="stylesheet">

  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css" integrity="sha512-iBBXm8fW90+nuLcSKlbmrPcLa0OT92xO1BIsZ+ywDWZCvqsWgccV3gFoRBv0z+8dLJgyAHIhR35VZc2oM/gI1w==" crossorigin="anonymous" referrerpolicy="no-referrer" />

</head>
<body>
	<!----hero Section start---->

	<div class="hero">

    <img class="wifi" src="/img/wifi.svg"/>
		<nav>
			<h2 class="logo">Project Data Collection</h2>
			<ul>
				<li><a href="../index.html">About Me</a></li>
				<li><a href="introduction.html">Introduction</a></li>
				<li><a href="Code.html">Code</a></li>
				<li><a href="Data.html">Data</a></li>
				<li><a href="DataGathering.html">Data Gathering</a></li>

			</ul>
		
		</nav>

		<div class="content">
			
			<h1>Data Gathering</h1>
			<h3>This section focuses on the methods used to gather the data discussed in the "Data" section</h3>
            <h4>Link to github repo with data + API (when ready)</h4>

			
		</div>
	</div>
	<!----Data collected ---->
	<section class="about">
		<div class="main">
		
			<div class="about-text">
				<h2>How was the data collected ?</h2>
				<p> Each dataset (found in this GitHub repository) was collected from a different source, all of which are explained below: <br>

                    1)	Music_df <br>
                    <br>

                        •	Billboard’s Top 100 (1950-2015): This dataset features the yearly top 100 songs (with their respective artist’s names) and was gathered from Reddit’s r/datasets by three GitHub users and posted in their private repository.
                        <br>
                        <br>
                        •	These files contain only 2 features per song, its name, and the name of the artist(s) behind it, which by themselves do not serve any valuable purpose. Since maximal analytical depth was one of the project's goals, it was important to gather many categorical and numerical features (all of which are explained in the data tab) of songs that each have a specific meaning and purpose.
                        <br>
                        <br>
                        •	Using Wikia Lyrics, as well as its Python counterpart on GitHub, Heroku API the GitHub users scraped each song's title/artist combination and downloaded the song's full lyrics. (I used a different method for data I collected later, details below)
                        <br>
                        <br>

                        •	Using the Natural Language Toolkit (NLTK) for Python, the GitHub users used the VADER model for parsimonious rule-based sentiment analysis of each song's lyrics. Each song was run through a sentiment analyzer and output an object with data about its sentiment: Negativity, Neutrality, Positivity
                        <br>
                        <br>
                        •	The textstat package in Python was used to calculate a number of aggregate readability metrics associated with each song's lyrics: number of words, number of lines, number of syllables, number of difficult words, fog and flesch index, and f_k_grade.
                        <br>
                        <br>
                        •	As for the music-related features (danceability, energy, key, loudness, mode, speechiness, acousticness, instrumentalness, liveness, valence, tempo, duration) are all features that are given by the Spotify Web API. Another GitHub user (link to repository) compiled all the above features with the Spotify API’s features into one large CSV file, called Music_df in the project’s GitHub repository.
                        <br>
                        <br>
                       
                     2)	Features_dataset
                     <br>
                     <br>
                        •	Since Music_df does not have a genre for each song, the three GitHub users mentioned above created a CSV file that associates each artist’s name with a genre, using the MusicBrainz API.
                        <br>
                        <br>
                        •	This dataset’s purpose is to eventually add a “genre” feature to the main dataset using some sort of “join” statement/function. This will be dealt with at the data cleaning stage of the project.
                        <br>
                        <br>

                    3)	Missingyears
                        <br>
                        <br>
                        •	As mentioned earlier, the music_df contains data for songs between 1950 and 2015, excluding the last 7 years (worth 700 songs) of music. For that reason, I had to do some extra work on my own to get this data as I believe significant changes in music have happened during that time period and it is essential to include it as part of the study.
                        <br>
                        <br>
                        •	The first step was importing Billboard’s Yearly Top 100 chart for the years 2016,2017,2018,2019,2020, and 2021. This was done using Billboard’s “unofficial” API, which was created by the following user and posted on GitHub. The charts for each year were scrapped and then combined using a Python script (found in my repo/add link).
                        <br>
                        <br>
                        •	Next, the lyrics for each (newly added) song were gathered using Genius’s  Python API called “lyricsgenius”.
                        <br>
                        <br>
                        •	All the remaining features for the newly added songs are being gathered by the moment and this page will be updated ASAP.
                        
                
                
                </p>
		
			</div>
		</div>
	

 


</body>
</html>