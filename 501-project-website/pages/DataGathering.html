<!DOCTYPE html>
<html>
<head>
	<title>Portfolio website</title>
	<link rel="stylesheet" type="text/css" href="../css/datagath_style.css">

	<link rel="preconnect" href="https://fonts.gstatic.com">
  <link href="https://fonts.googleapis.com/css2?family=Josefin+Sans:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;1,100;1,200;1,300;1,400;1,500;1,600;1,700&display=swap" rel="stylesheet">
  <meta http-equiv="Content-Type" content="charset=UTF-8" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css" integrity="sha512-iBBXm8fW90+nuLcSKlbmrPcLa0OT92xO1BIsZ+ywDWZCvqsWgccV3gFoRBv0z+8dLJgyAHIhR35VZc2oM/gI1w==" crossorigin="anonymous" referrerpolicy="no-referrer" />

</head>
<body>
	<!----hero Section start---->

	<div class="hero">

    <img class="wifi" src="../img/db.svg"/>
		<nav>
			<h2 class="logo">Data Collection</h2>
			<ul>
        <li><a href="../index.html">About Me</a></li>
        <li><a href="introduction.html">Introduction</a></li>
        <li><a href="Code.html">Code</a></li>
        <li><div class="dropdown">
          <button class="dropbtn">Data 
          <i class="fa fa-caret-down"></i>
          </button>
          <div class="dropdown-content">
          <a href="Data.html">Data</a>
          <a href="DataGathering.html">Data Gathering</a>
          <a href="DataCleaning.html">Data Cleaning</a>
          </div>
        </div></li>
        <li><a href="ExploringData.html">Exploring Data</a></li>
        <li><div class="dropdown">
          <button class="dropbtn" style="padding-top: 30%;">Models 
          <i class="fa fa-caret-down"></i>
          </button>
          <div class="dropdown-content">
          <a href="naivebayes.html">Naive Bayes</a>
          <a href="Decision_tree.html">Decision Tree</a>
          <a href="SVM.html">SVM</a>
          <a href="Clustering.html">Clustering</a>
          <a href="ARM.html">ARM</a>
    
          </div>
    
        </div></li>
        <li><a href="Product.html">Product</a></li>
        <li><a href="Conclusions.html">Conclusions</a></li>
    
			</ul>
		
		</nav>

		<div class="content">
			
			<h1>Data Gathering</h1>
			<h3>This section focuses on the methods used to gather the data discussed in the "Data" section</h3>
            <h4><a href="https://github.com/anly501/anly-501-project-anthonymoub/tree/main/501-project-website" style="color: rgb(39, 160, 204)">Link </a> to Github repo with datasets and API scripts</h4>

		</div>
	</div>
	<!----Data collected ---->
	<section class="about">
		<div class="main">
		
			<div class="about-text">
				<h2 style="text-align: left">How was the data collected ?</h2>
        <br>
				<p> The main datasets for this project are: <br><br>

          &#x2022; features_data.csv <br>
          &#x2022; music_df.csv <br>
          &#x2022; missingyears.csv <br>
          &#x2022; missingyears_updated.csv <br> 
          &#x2022; anthony_music.csv <br> 
          &#x2022; rnb.csv <br> 
          &#x2022; techno.csv <br> 
          &#x2022; hiphop.csv <br><br>
           
          Each dataset was collected from a different source using different methods, all of which are explained below: <br><br>

                    1)	Music_df <br>
                    <br>

                        _	Billboard’s Top 100 (1950-2015): This dataset features the yearly top 100 songs (with their respective artist’s names) 
                        and was gathered from Reddit’s r/datasets by three GitHub users and posted in <a href="https://github.com/kevinschaich/billboard " style="color: rgb(39, 160, 204)">their</a>  private repository.
                        <br>
                        <br>
                        _	These files contain only 2 features per song, its name, and the name of the artist(s) behind it, which by themselves do not serve any valuable purpose. Since maximal analytical depth is one of the project's goals, it was important to gather many categorical and numerical features (all of which are explained in the data tab) of songs that each have a specific meaning and purpose.
                        <br>
                        <br>
                        _	Using Wikia Lyrics, as well as its Python counterpart on GitHub, Heroku API the GitHub users scraped each song's title/artist combination and downloaded the song's full lyrics. (I used a different method for data I collected later, details below)
                        <br>
                        <br>

                        _	Using the Natural Language Toolkit (NLTK) for Python, the GitHub users used the VADER model for parsimonious rule-based sentiment analysis of each song's lyrics. Each song was run through a sentiment analyzer and output an object with data about its sentiment: Negativity, Neutrality, Positivity
                        <br>
                        <br>
                        _	The textstat package in Python was used to calculate a number of aggregate readability metrics associated with each song's lyrics: number of words, number of lines, number of syllables, number of difficult words, fog and flesch index, and f_k_grade.
                        <br>
                        <br>
                        _	As for the music-related features (danceability, energy, key, loudness, mode, speechiness, acousticness, instrumentalness, liveness, valence, tempo, duration) are all features that are given by the Spotify Web API. Another GitHub user <a href="https://github.com/RosebudAnwuri/TheArtandScienceofData/tree/master/The%20Making%20of%20Great%20Music" style="color: rgb(39, 160, 204)">(Link to repository)</a> compiled all the above features with the Spotify API’s features into one large CSV file, called Music_df in the project’s GitHub repository.
                        <br>
                        <br>
                       
                     2)	Features_dataset
                     <br>
                     <br>
                        _	Since Music_df does not have a genre for each song, the three GitHub users mentioned above created a CSV file that associates each artist’s name with a genre, using the MusicBrainz API.
                        <br>
                        <br>
                        _	This dataset’s purpose is to eventually add a “genre” feature to the main dataset using some sort of “join” statement/function. This will be dealt with at the data cleaning stage of the project.
                        <br>
                        <br>

                    3)	Missingyears
                        <br>
                        <br>
                        _	As mentioned earlier, the music_df contains data for songs between 1950 and 2015, excluding the last 7 years (worth 700 songs) of music. For that reason, I had to do some extra work on my own to get this data as I believe significant changes in music have happened during that time period and it is essential to include it as part of the study.
                        <br>
                        <br>
                        _	The first step was importing Billboard’s Yearly Top 100 chart for the years 2016,2017,2018,2019,2020, and 2021. This was done using Billboard’s “unofficial” API, which was created by <a href="https://github.com/guoguo12/billboard-charts" style="color: rgb(39, 160, 204)">following</a>  user and posted on GitHub. The charts for each year were scrapped and then combined using a Python script (found in my repo).
                        <br>
                        <br>
                        _	Next, the lyrics for each (newly added) song were gathered using Genius’s  Python API called “lyricsgenius”.
                        <br>
                        <br>
                        _	This resulted in an updated dataset with all the new music and their respective lyrics. The last missing piece was getting
                        the songs' audio features.

                        <br>
                        <br>
                        
                    4)	Missingyears_updated  

                    <br>
                    <br>

                    _	I gathered the audio features of newly added songs using the Spotify API and R. This resulted in me now having a dataset identical
                    to what i have gathered from Github but for the missing years.
                
                    _	The next step is cleaning all the data gathered and combining all data into one central data set.

                    <br>
                    <br>


                    5)	anthony_music  

                    <br>
                    <br>

                    _	This dataset is just a csv version of my Spotify playlist with all the features audio related 
                    features the Spotify API provides. 
                
                    _	This dataset was gathered from Exportify (insert link), a website where any user can connect their 
                    Spotify account to and get all the audio features for their playlist.

                    <br>
                    <br>

                    6)	rnb/techno/hiphop   

                    <br>
                    <br>

                    _	All of the 3 datasets above where gathered in the same manner. <br><br>
                
                    _	I got these 3 playlists by browsing Spotify and inputting them into Exportify to get all 
                    the features.

                    <br><br>

                    All of the datasets collected were used for different purposes and models throughout the project.

                    <br><br>

                    Note: There are some extra files that were gathered, but they were very specific to the model being 
                    built at the time and do not represent a core aspect of this project.


                
                </p>
		
			</div>
		</div>
	

 


</body>
</html>