counter <- 0
while (single_toss_simulator() == 0){
counter <- counter + 1}
print(counter)}
my_attempts()
my_attempts <- function() {
counter <- 0
while (single_toss_simulator() == 0){
counter <- counter + 1}
return(counter)}
my_attempts()
single_toss_simulator()
single_toss_simulator()
single_toss_simulator()
single_toss_simulator()
single_toss_simulator()
single_toss_simulator()
single_toss_simulator()
my_attempts = function() {
counter <- 0
while (single_toss_simulator() == 0){counter <- counter + 1}
return(counter)}
my_attempts()
myattempts = function(p){ counter <- 0
while (single_toss_simulator() == 0){ counter <- counter + 1 } return(counter) }
myattempts = function(p){
counter <- 0
while (single_toss_simulator() == 0){ counter <- counter + 1 }
return(counter) }
my_attempts()
myattempts = function(){
counter <- 0
while (single_toss_simulator() == 0){ counter <- counter + 1 }
return(counter) }
myattempts()
myattempts()
myattempts()
myattempts = function(){
counter <- 0
while (single_toss_simulator() == 0){ counter <- counter + 1 }
return(counter) }
myattempts()
myattempts = function(){
counter <- 0
while (single_toss_simulator() == 0){ counter <- counter + 1 }
return(counter) }
myattempts()
mytoss = function(p){
u <- runif(1)
x <- as.numeric(u < p)#when p is the larger number, there is a higher chance of being th return(x)
}
myattempts = function(p){ counter <- 0
while (mytoss(p) == 0){ counter <- counter + 1 } return(counter) }
myattempts = function(p){ counter <- 0
while (mytoss(p) == 0){ counter <- counter + 1 }
return(counter) }
myattempts(.2)
single_toss_simulator()
my_attempts()
single_toss_simulator()
while (single_toss_simulator() == 0) {print('hi')}
my_attempts()
my_attempts()
my_attempts()
my_attempts()
my_attempts()
my_attempts()
my_attempts()
my_attempts()
my_attempts()
my_attempts()
my_attempts()
single_toss_simulator()
single_toss_simulator()
single_toss_simulator()
single_toss_simulator()
single_toss_simulator()
single_toss_simulator()
single_toss_simulator <- function (){
p <- runif(1,min = 0 , max = 1)
q <- 1 - p
result <- as.numeric(sample(c("1" , "0") , 1, prob = c(p , q)))
return(result)
}
my_attempts = function() {
counter <- 0
while (single_toss_simulator() == 0){counter <- counter + 1}
return(counter)}
my_attempts()
my_attempts()
my_attempts()
my_attempts()
my_attempts()
my_attempts()
library(httr)
response = POST(
'https://accounts.spotify.com/api/token',
accept_json(),
authenticate(clientID, secret),
body = list(grant_type = 'client_credentials'),
encode = 'form',
verbose()
)
clientID = '692079d1737048de99769798cb46dc20'
secret = '5b3f80e96a4f4a338c8733951d399d69'
response = POST(
'https://accounts.spotify.com/api/token',
accept_json(),
authenticate(clientID, secret),
body = list(grant_type = 'client_credentials'),
encode = 'form',
verbose()
)
mytoken = content(response)$access_token
HeaderValue = paste0('Bearer ', mytoken)
HeaderValue
res <- VERB("GET", url = "https://api.spotify.com/v1/search?q=track" + 'despacito' + '"%20artist:"' + 'bieber' + "&type=track" )
df <- read.csv("/Users/anthonymoubarak/Desktop/Project/Project Data/missingyears_updated.csv")
#name of Spotify Features
features_name=c("id","danceability","energy","key","loudness","mode","speechiness",
"acousticness","instrumentalness","liveness","valence","tempo",
"duration_ms","time_signature","uri","analysis_url")
#Initiatilizing the features in the data
df[,c("id","danceability","energy","key","loudness","mode","speechiness",
"acousticness","instrumentalness","liveness","valence","tempo",
"duration_ms","time_signature","uri","analysis_url")]=0
View(df)
library(Rspotify)
installed.packages(Rspotify)
installed.packages("Rspotify")
install_github("tiagomendesdantas/Rspotify")
library(devtools)
install_github("tiagomendesdantas/Rspotify")
keys <- spotifyOAuth(app_id="ANLY501_PROJECT",clientID,secret)
library(Rspotify)
keys <- spotifyOAuth(app_id="ANLY501_PROJECT",clientID,secret)
keys <- spotifyOAuth(app_id="ANLY501_PROJECT","692079d1737048de99769798cb46dc20","5b3f80e96a4f4a338c8733951d399d69")
keys <- spotifyOAuth(app_id="ANLY501_PROJECT","692079d1737048de99769798cb46dc20","5b3f80e96a4f4a338c8733951d399d69")
keys <- spotifyOAuth(app_id="ANLY501_PROJECT","692079d1737048de99769798cb46dc20","5b3f80e96a4f4a338c8733951d399d69")
keys <- spotifyOAuth(app_id="ANLY501_PROJECT","692079d1737048de99769798cb46dc20","5b3f80e96a4f4a338c8733951d399d69")
mytoken
HeaderValue
header = {"Authorization":HeaderValue}
HeaderValue = paste0('Bearer ', mytoken)
header = {"Authorization":HeaderValue}
HeaderValue = paste0('Bearer ', mytoken)
HeaderValue
clientID = '692079d1737048de99769798cb46dc20'
secret = '5b3f80e96a4f4a338c8733951d399d69'
response = POST(
'https://accounts.spotify.com/api/token',
accept_json(),
authenticate(clientID, secret),
body = list(grant_type = 'client_credentials'),
encode = 'form',
verbose()
)
mytoken = content(response)$access_token
HeaderValue = paste0('Bearer ', mytoken)
header = {"Authorization":HeaderValue}
df <- read.csv("/Users/anthonymoubarak/Desktop/Project/Project Data/missingyears_updated.csv")
#name of Spotify Features
features_name=c("id","danceability","energy","key","loudness","mode","speechiness",
"acousticness","instrumentalness","liveness","valence","tempo",
"duration_ms","time_signature","uri","analysis_url")
#Initiatilizing the features in the data
df[,c("id","danceability","energy","key","loudness","mode","speechiness",
"acousticness","instrumentalness","liveness","valence","tempo",
"duration_ms","time_signature","uri","analysis_url")]=0
keys <- spotifyOAuth(app_id="ANLY501_PROJECT","692079d1737048de99769798cb46dc20","5b3f80e96a4f4a338c8733951d399d69")
View(df)
df <- read.csv("/Users/anthonymoubarak/Desktop/Project/Project Data/missingyears_updated.csv")
#name of Spotify Features
features_name=c("id","danceability","energy","key","loudness","mode","speechiness",
"acousticness","instrumentalness","liveness","valence","tempo",
"duration_ms","time_signature","uri","analysis_url")
#Initiatilizing the features in the data
df[,c("id","danceability","energy","key","loudness","mode","speechiness",
"acousticness","instrumentalness","liveness","valence","tempo",
"duration_ms","time_signature","uri","analysis_url")]=0
View(df)
tracks_list <- read.csv("/Users/anthonymoubarak/Desktop/Project/Project Data/missingyears_updated.csv")
#name of Spotify Features
features_name=c("id","danceability","energy","key","loudness","mode","speechiness",
"acousticness","instrumentalness","liveness","valence","tempo",
"duration_ms","time_signature","uri","analysis_url")
#Initiatilizing the features in the data
tracks_list[,c("id","danceability","energy","key","loudness","mode","speechiness",
"acousticness","instrumentalness","liveness","valence","tempo",
"duration_ms","time_signature","uri","analysis_url")]=0
for(i in 1:nrow(tracks_list)){
Sys.sleep(0.10)
track_URI2 = paste0('https://api.spotify.com/v1/audio-features/',
tracks_list$id[i])
track_response2 = GET(url = track_URI2,
add_headers(Authorization = HeaderValue))
tracks2 = content(track_response2)
tracks_list$key[i] <- tracks2$key
tracks_list$mode[i] <- tracks2$mode
tracks_list$time_signature[i] <- tracks2$time_signature
tracks_list$acousticness[i] <- tracks2$acousticness
tracks_list$danceability[i] <- tracks2$danceability
tracks_list$energy[i] <- tracks2$energy
tracks_list$instrumentalness[i] <- tracks2$instrumentalness
tracks_list$liveliness[i] <- tracks2$liveness
tracks_list$loudness[i] <- tracks2$loudness
tracks_list$speechiness[i] <- tracks2$speechiness
tracks_list$valence[i] <- tracks2$valence
tracks_list$tempo[i] <- tracks2$tempo
}
View(tracks_list)
for(i in 1:nrow(tracks_list)){
Sys.sleep(0.10)
track_URI2 = paste0('https://api.spotify.com/v1/audio-features/',
tracks_list$spotify_id[i])
track_response2 = GET(url = track_URI2,
add_headers(Authorization = HeaderValue))
tracks2 = content(track_response2)
tracks_list$key[i] <- tracks2$key
tracks_list$mode[i] <- tracks2$mode
tracks_list$time_signature[i] <- tracks2$time_signature
tracks_list$acousticness[i] <- tracks2$acousticness
tracks_list$danceability[i] <- tracks2$danceability
tracks_list$energy[i] <- tracks2$energy
tracks_list$instrumentalness[i] <- tracks2$instrumentalness
tracks_list$liveliness[i] <- tracks2$liveness
tracks_list$loudness[i] <- tracks2$loudness
tracks_list$speechiness[i] <- tracks2$speechiness
tracks_list$valence[i] <- tracks2$valence
tracks_list$tempo[i] <- tracks2$tempo
}
tracks_list <- read.csv("/Users/anthonymoubarak/Desktop/Project/Project Data/missingyears_updated.csv")
#name of Spotify Features
features_name=c("id","danceability","energy","key","loudness","mode","speechiness",
"acousticness","instrumentalness","liveness","valence","tempo",
"duration_ms","time_signature","uri","analysis_url")
#Initiatilizing the features in the data
tracks_list[,c("id","danceability","energy","key","loudness","mode","speechiness",
"acousticness","instrumentalness","liveness","valence","tempo",
"duration_ms","time_signature","uri","analysis_url")]=0
for(i in 1:nrow(tracks_list)){
Sys.sleep(0.10)
track_URI2 = paste0('https://api.spotify.com/v1/audio-features/',
tracks_list$spotify_id[i])
track_response2 = GET(url = track_URI2,
add_headers(Authorization = HeaderValue))
tracks2 = content(track_response2)
tracks_list$key[i] <- tracks2$key
tracks_list$mode[i] <- tracks2$mode
tracks_list$time_signature[i] <- tracks2$time_signature
tracks_list$acousticness[i] <- tracks2$acousticness
tracks_list$danceability[i] <- tracks2$danceability
tracks_list$energy[i] <- tracks2$energy
tracks_list$instrumentalness[i] <- tracks2$instrumentalness
tracks_list$liveliness[i] <- tracks2$liveness
tracks_list$loudness[i] <- tracks2$loudness
tracks_list$speechiness[i] <- tracks2$speechiness
tracks_list$valence[i] <- tracks2$valence
tracks_list$tempo[i] <- tracks2$tempo
}
View(tracks_list)
write.csv(tracks_list, "/Users/anthonymoubarak/Desktop/Project/Project Data/missingyears_updated.csv", row.names=FALSE)
tracks_list <- read.csv("/Users/anthonymoubarak/Desktop/Project/Project Data/missingyears_updated.csv")
View(tracks_list)
#Initiatilizing the features in the data
tracks_list[,c("id","danceability","energy","key","loudness","mode","speechiness",
"acousticness","instrumentalness","liveness","valence","tempo",
"duration_ms","time_signature","uri","analysis_url")]=0
for(i in 1:nrow(tracks_list)){
Sys.sleep(0.10)
track_URI2 = paste0('https://api.spotify.com/v1/audio-features/',
tracks_list$spotify_id[i])
track_response2 = GET(url = track_URI2,
add_headers(Authorization = HeaderValue))
tracks2 = content(track_response2)
tracks_list$key[i] <- tracks2$key
tracks_list$mode[i] <- tracks2$mode
tracks_list$time_signature[i] <- tracks2$time_signature
tracks_list$acousticness[i] <- tracks2$acousticness
tracks_list$danceability[i] <- tracks2$danceability
tracks_list$energy[i] <- tracks2$energy
tracks_list$instrumentalness[i] <- tracks2$instrumentalness
tracks_list$liveliness[i] <- tracks2$liveness
tracks_list$loudness[i] <- tracks2$loudness
tracks_list$speechiness[i] <- tracks2$speechiness
tracks_list$valence[i] <- tracks2$valence
tracks_list$tempo[i] <- tracks2$tempo
tracks2$duration_ms[i] <- tracks2$duration_ms
}
tracks_list <- read.csv("/Users/anthonymoubarak/Desktop/Project/Project Data/missingyears_updated.csv")
#name of Spotify Features
features_name=c("id","danceability","energy","key","loudness","mode","speechiness",
"acousticness","instrumentalness","liveness","valence","tempo",
"duration_ms","time_signature","uri","analysis_url")
#Initiatilizing the features in the data
tracks_list[,c("id","danceability","energy","key","loudness","mode","speechiness",
"acousticness","instrumentalness","liveness","valence","tempo",
"duration_ms","time_signature","uri","analysis_url")]=0
for(i in 1:nrow(tracks_list)){
Sys.sleep(0.10)
track_URI2 = paste0('https://api.spotify.com/v1/audio-features/',
tracks_list$spotify_id[i])
track_response2 = GET(url = track_URI2,
add_headers(Authorization = HeaderValue))
tracks2 = content(track_response2)
tracks_list$key[i] <- tracks2$key
tracks_list$mode[i] <- tracks2$mode
tracks_list$time_signature[i] <- tracks2$time_signature
tracks_list$acousticness[i] <- tracks2$acousticness
tracks_list$danceability[i] <- tracks2$danceability
tracks_list$energy[i] <- tracks2$energy
tracks_list$instrumentalness[i] <- tracks2$instrumentalness
tracks_list$liveliness[i] <- tracks2$liveness
tracks_list$loudness[i] <- tracks2$loudness
tracks_list$speechiness[i] <- tracks2$speechiness
tracks_list$valence[i] <- tracks2$valence
tracks_list$tempo[i] <- tracks2$tempo
tracks_list$duration_ms[i] <- tracks2$duration_ms
}
write.csv(tracks_list, "/Users/anthonymoubarak/Desktop/Project/Project Data/missingyears_updated.csv", row.names=FALSE)
tracks_list <- read.csv("/Users/anthonymoubarak/Desktop/Project/Project Data/missingyears_updated.csv")
#name of Spotify Features
features_name=c("id","danceability","energy","key","loudness","mode","speechiness",
"acousticness","instrumentalness","liveness","valence","tempo",
"duration_ms","time_signature","uri","analysis_url")
#Initiatilizing the features in the data
tracks_list[,c("id","danceability","energy","key","loudness","mode","speechiness",
"acousticness","instrumentalness","liveness","valence","tempo",
"duration_ms","time_signature","uri","analysis_url")]=0
for(i in 1:nrow(tracks_list)){
Sys.sleep(0.10)
track_URI2 = paste0('https://api.spotify.com/v1/audio-features/',
tracks_list$spotify_id[i])
track_response2 = GET(url = track_URI2,
add_headers(Authorization = HeaderValue))
tracks2 = content(track_response2)
tracks_list$key[i] <- tracks2$key
tracks_list$mode[i] <- tracks2$mode
tracks_list$time_signature[i] <- tracks2$time_signature
tracks_list$acousticness[i] <- tracks2$acousticness
tracks_list$danceability[i] <- tracks2$danceability
tracks_list$energy[i] <- tracks2$energy
tracks_list$instrumentalness[i] <- tracks2$instrumentalness
tracks_list$liveness[i] <- tracks2$liveness
tracks_list$loudness[i] <- tracks2$loudness
tracks_list$speechiness[i] <- tracks2$speechiness
tracks_list$valence[i] <- tracks2$valence
tracks_list$tempo[i] <- tracks2$tempo
tracks_list$duration_ms[i] <- tracks2$duration_ms
}
write.csv(tracks_list, "/Users/anthonymoubarak/Desktop/Project/Project Data/missingyears_updated.csv", row.names=FALSE)
df_loans = read('../data/loans.csv')
# Import data
df_loans = read.csv('../data/loans.csv')
df_loans = read.csv('../data/loans.csv')
df_genres <- read.csv("Data/features_dataset.csv")
getwd()
setwd("/Users/anthonymoubarak/Desktop/anly-501-project-anthonymoub/501-project-website")
df_genres <- read.csv("Data/features_dataset.csv")
df_genres
drops <- c("FeaturedArtists" , "featured_genre")
df_genres <- df_genres[ , !(names(df_genres) %in% drops)]
df_genres
names(finaldf)
# Before combinining the new dataframe (songs post 2015) with the old dataframe, we should make sure everything is clean in both datasets
# Start by cleaning the new dataset since the old one has been probably cleaned by the GitHub users
new_songs <- read.csv('Data/new_music.csv')
# Start by checking all the columns we have and drop the unwanted ones
names(new_songs)
# Columns that are if no use: X (useless), spotify_id (no longer useful at this point), id (useless is just a byproduct of previous operations)
# url, and analysis url (both are useless)
drops <- c("X.1","spotify_id", "id", "uri" , "analysis_url")
new_songs <- new_songs[ , !(names(new_songs) %in% drops)]
# Next, we need to check the datatype of each column and make sure everything is the in the desired data type
str(new_songs)
# All columns/variables are of the correct data types for us to use in EDA and model development
# The next step is dealing with missing values,which are present in a couple of entries of the lyrics column.
# All songs with missing lyrics will be dropped as they are a small number (183) out of all the songs gathered.
# The absence of these songs will have a very small (if any) effect on the analysis, which is why they will be
# dropped.
sum(new_songs$lyrics == "") # Number of songs with missing lyrics
new_songs <- new_songs[!(new_songs$lyrics == ""  ) , ]
# Do th same for the old music dataframe (so we can join them later)
old_songs <- read.csv('Data/music_df.csv')
# Check the columns of this dataframe
names(old_songs)
# Dropping columns that are of no use
drops <- c("spotify_id", "id", "uri" , "analysis_url" , "artist_with_features", "year_bin", "image", "cluster","Gender" , "num_dupes")
old_songs <- old_songs[ , !(names(old_songs) %in% drops)]
names(old_songs)
names(new_songs)
old_songs <- old_songs[!(old_songs$lyrics == ""  ) , ]
# Next we need to reorder the new songs dataframe to match the old songs dataframe so we could merge
# the two together
names(old_songs)
new_songs <- new_songs[, c("lyrics", "num_syllables","pos" ,"year" , "fog_index" ,"flesch_index" ,"num_words","num_lines","title","f_k_grade",
"artist" ,"difficult_words",  "neg" , "neu" , "compound","danceability","energy","key","loudness" ,"mode","speechiness",
"acousticness","instrumentalness" ,"liveness" ,"valence"  , "tempo" , "duration_ms" , "time_signature" )]
# Genre gathering
df_genres <- read.csv("Data/features_dataset.csv")
drops <- c("FeaturedArtists" , "featured_genre")
df_genres <- df_genres[ , !(names(df_genres) %in% drops)]
# The final step is appending the new music dataset to the old music dataset to have our final combined dataset
finaldf <- rbind(old_songs , new_songs)
# Save this final df to a csv
#write.csv(finaldf , "Data/final_df.csv")
# Part 2 of data cleaning is done in a .ipynb notebook and deals with handling text data (lyrics)
names(finaldf)
x<-merge(x=finaldf,y=df_genres,by="artist",all.x=TRUE)
x
tail(x)
x
finaldf
x<-merge(x=finaldf,y=df_genres,by="artist",all.x=TRUE)
x
df_genres
x
x<-merge(finaldf,df_genres,by="artist")
x
tail(x)
tail(df_genres)
df_genres[!duplicated(df_genres$artist), ]
df_genres
df_genres <- df_genres[!duplicated(df_genres$artist), ]
x<-merge(finaldf,df_genres,by="artist")
x
tail(x)
write.csv(x , "Data/x")
x<-data.frame(merge(finaldf,df_genres,by="artist"))
x
write.csv(x , "Data/x.csv")
x <- 0:50
plot(x,dbinom(x,size=50,prob=.33),type="h")
x <- 0:50
plot(x,dbinom(x,size=50,prob=.33),type="h")
str(new_songs)
new_songs <- read.csv('Data/new_music.csv')
# Start by checking all the columns we have and drop the unwanted ones
names(new_songs)
# Columns that are if no use: X (useless), spotify_id (no longer useful at this point), id (useless is just a byproduct of previous operations)
# url, and analysis url (both are useless)
drops <- c("X.1","spotify_id", "id", "uri" , "analysis_url")
new_songs <- new_songs[ , !(names(new_songs) %in% drops)]
# Next, we need to check the datatype of each column and make sure everything is the in the desired data type
str(new_songs)
# All columns/variables are of the correct data types for us to use in EDA and model development
# The next step is dealing with missing values,which are present in a couple of entries of the lyrics column.
# All songs with missing lyrics will be dropped as they are a small number (183) out of all the songs gathered.
# The absence of these songs will have a very small (if any) effect on the analysis, which is why they will be
# dropped.
sum(new_songs$lyrics == "") # Number of songs with missing lyrics
new_songs <- new_songs[!(new_songs$lyrics == ""  ) , ]
# Do th same for the old music dataframe (so we can join them later)
old_songs <- read.csv('Data/music_df.csv')
# Check the columns of this dataframe
names(old_songs)
# Dropping columns that are of no use
drops <- c("spotify_id", "id", "uri" , "analysis_url" , "artist_with_features", "year_bin", "image", "cluster","Gender" , "num_dupes")
old_songs <- old_songs[ , !(names(old_songs) %in% drops)]
names(old_songs)
names(new_songs)
old_songs <- old_songs[!(old_songs$lyrics == ""  ) , ]
# Next we need to reorder the new songs dataframe to match the old songs dataframe so we could merge
# the two together
names(old_songs)
new_songs <- new_songs[, c("lyrics", "num_syllables","pos" ,"year" , "fog_index" ,"flesch_index" ,"num_words","num_lines","title","f_k_grade",
"artist" ,"difficult_words",  "neg" , "neu" , "compound","danceability","energy","key","loudness" ,"mode","speechiness",
"acousticness","instrumentalness" ,"liveness" ,"valence"  , "tempo" , "duration_ms" , "time_signature" )]
# The final step is appending the new music dataset to the old music dataset to have our final combined dataset
finaldf <- rbind(old_songs , new_songs)
# Save this final df to a csv
write.csv(finaldf , "Data/final_df.csv")
# Before combinining the new dataframe (songs post 2015) with the old dataframe, we should make sure everything is clean in both datasets
# Start by cleaning the new dataset since the old one has been probably cleaned by the GitHub users
new_songs <- read.csv('Data/new_music.csv')
# Start by checking all the columns we have and drop the unwanted ones
names(new_songs)
# Columns that are if no use: X (useless), spotify_id (no longer useful at this point), id (useless is just a byproduct of previous operations)
# url, and analysis url (both are useless)
drops <- c("X.1","spotify_id", "id", "uri" , "analysis_url")
new_songs <- new_songs[ , !(names(new_songs) %in% drops)]
# Next, we need to check the datatype of each column and make sure everything is the in the desired data type
str(new_songs)
# All columns/variables are of the correct data types for us to use in EDA and model development
# The next step is dealing with missing values,which are present in a couple of entries of the lyrics column.
# All songs with missing lyrics will be dropped as they are a small number (183) out of all the songs gathered.
# The absence of these songs will have a very small (if any) effect on the analysis, which is why they will be
# dropped.
sum(new_songs$lyrics == "") # Number of songs with missing lyrics
new_songs <- new_songs[!(new_songs$lyrics == ""  ) , ]
# Do th same for the old music dataframe (so we can join them later)
old_songs <- read.csv('Data/music_df.csv')
# Check the columns of this dataframe
names(old_songs)
# Dropping columns that are of no use
drops <- c("spotify_id", "id", "uri" , "analysis_url" , "artist_with_features", "year_bin", "image", "cluster","Gender" , "num_dupes")
old_songs <- old_songs[ , !(names(old_songs) %in% drops)]
names(old_songs)
names(new_songs)
old_songs <- old_songs[!(old_songs$lyrics == ""  ) , ]
# Next we need to reorder the new songs dataframe to match the old songs dataframe so we could merge
# the two together
names(old_songs)
new_songs <- new_songs[, c("lyrics", "num_syllables","pos" ,"year" , "fog_index" ,"flesch_index" ,"num_words","num_lines","title","f_k_grade",
"artist" ,"difficult_words",  "neg" , "neu" , "compound","danceability","energy","key","loudness" ,"mode","speechiness",
"acousticness","instrumentalness" ,"liveness" ,"valence"  , "tempo" , "duration_ms" , "time_signature" )]
# The final step is appending the new music dataset to the old music dataset to have our final combined dataset
finaldf <- rbind(old_songs , new_songs)
# Save this final df to a csv
write.csv(finaldf , "Data/final_df.csv")
finaldf
View(finaldf)
